{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d16b10",
   "metadata": {},
   "source": [
    "# RDFSolve: PDB RDF - no counts\n",
    "\n",
    "This notebook demonstrates faster schema discovery:\n",
    "1. Setting up an endpoint and graph\n",
    "2. Generating fast VoID descriptions using CONSTRUCT queries **without** COUNT aggregations\n",
    "3. Extracting schema from the VoID description\n",
    "4. Analyzing the results as DataFrame and JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cfa4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdfsolve.rdfsolve import RDFSolver\n",
    "from rdfsolve.void_parser import VoidParser, generate_void_from_endpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e8e7d",
   "metadata": {},
   "source": [
    "## Step 1: Configure Dataset Parameters\n",
    "\n",
    "We'll configure the PDB dataset with its SPARQL endpoint and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807c1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: pdb\n",
      "Endpoint: https://rdfportal.org/pdb/sparql\n",
      "VoID IRI: http://rdfportal.org/dataset/pdbj\n",
      "Graph URI: http://rdfportal.org/dataset/pdbj\n",
      "Mode: Complete (with COUNT aggregations)\n"
     ]
    }
   ],
   "source": [
    "# AOPWIKI configuration\n",
    "endpoint_url = \"https://rdfportal.org/pdb/sparql\"\n",
    "dataset_name = \"pdb\"\n",
    "void_iri = \"http://rdfportal.org/dataset/pdbj\"\n",
    "graph_uri = \"http://rdfportal.org/dataset/pdbj\"  # Specify the correct graph URI\n",
    "working_path = \".\"\n",
    "\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Endpoint: {endpoint_url}\")\n",
    "print(f\"VoID IRI: {void_iri}\")\n",
    "print(f\"Graph URI: {graph_uri}\")\n",
    "print(f\"Mode: Complete (with COUNT aggregations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e4ae88",
   "metadata": {},
   "source": [
    "## Step 2: Initialize RDFSolver\n",
    "\n",
    "Create an RDFSolver instance with our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b3caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDFSolver initialized successfully\n",
      "Endpoint: https://rdfportal.org/pdb/sparql\n",
      "Dataset: pdb\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize RDFSolver with our configuration\n",
    "    solver = RDFSolver(\n",
    "        endpoint=endpoint_url,\n",
    "        path=working_path,\n",
    "        void_iri=void_iri,\n",
    "        dataset_name=dataset_name\n",
    "    )\n",
    "    \n",
    "    print(\"RDFSolver initialized successfully\")\n",
    "    print(f\"Endpoint: {solver.endpoint}\")\n",
    "    print(f\"Dataset: {solver.dataset_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0124951",
   "metadata": {},
   "source": [
    "## Step 3: Generate Fast VoID Description\n",
    "\n",
    "Generate VoID **without** COUNT aggregations for fast discovery. This is much faster but doesn't provide count statistics.\n",
    "\n",
    "Three CONSTRUCT queries get the partitions for classes, properties, and datatypes using SELECT DISTINCT instead of COUNT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8db9486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating VoID from endpoint: https://rdfportal.org/pdb/sparql\n",
      "Using graph URI: http://rdfportal.org/dataset/pdbj\n",
      "Fast mode: Skipping COUNT aggregations\n",
      "üöÄ Starting VoID extraction from SPARQL endpoint\n",
      "üì° Endpoint: https://rdfportal.org/pdb/sparql\n",
      "üéØ Graph: http://rdfportal.org/dataset/pdbj\n",
      "üîß Mode: Traditional VoID (SPARQL processing)\n",
      "============================================================\n",
      "üîÑ Starting query: class_partitions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished query: class_partitions (took 2.29s)\n",
      "üìä Parsing results for class_partitions...\n",
      "üîÑ Starting query: property_partitions\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Generate fast VoID without count aggregations\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     fast_void_graph = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvoid_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgraph_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_void.ttl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Fast discovery without counts\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGraph contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(fast_void_graph)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m triples\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_void.ttl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rdfsolve-1/src/rdfsolve/rdfsolve.py:165\u001b[39m, in \u001b[36mRDFSolver.void_generator\u001b[39m\u001b[34m(self, graph_uri, output_file, counts, sample_limit)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_limit:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing sample limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_limit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m void_graph = \u001b[43mVoidParser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_void_from_sparql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_endpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_limit\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m._void = void_graph\n\u001b[32m    170\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mVoID generation completed successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rdfsolve-1/src/rdfsolve/void_parser.py:852\u001b[39m, in \u001b[36mVoidParser.generate_void_from_sparql\u001b[39m\u001b[34m(endpoint_url, graph_uri, output_file, counts, sample_limit, raw_extraction)\u001b[39m\n\u001b[32m    849\u001b[39m     successful_queries += \u001b[32m1\u001b[39m\n\u001b[32m    850\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mproperty_partitions\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[32m    851\u001b[39m     \u001b[38;5;66;03m# Standard single property query (optional due to performance)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m     query_count += \u001b[32m1\u001b[39m\n\u001b[32m    853\u001b[39m     run_construct(queries[\u001b[33m'\u001b[39m\u001b[33mproperty_partitions\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    854\u001b[39m                   \u001b[33m\"\u001b[39m\u001b[33mproperty_partitions\u001b[39m\u001b[33m\"\u001b[39m, is_optional=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    855\u001b[39m     successful_queries += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rdfsolve-1/src/rdfsolve/void_parser.py:765\u001b[39m, in \u001b[36mVoidParser.generate_void_from_sparql.<locals>.run_construct\u001b[39m\u001b[34m(query_text, name, is_optional)\u001b[39m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    763\u001b[39m     \u001b[38;5;66;03m# For very long queries, we'd need threading to monitor progress\u001b[39;00m\n\u001b[32m    764\u001b[39m     \u001b[38;5;66;03m# But for now, we'll just time the execution\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     results = \u001b[43msparql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.convert()\n\u001b[32m    766\u001b[39m     dt = time.monotonic() - t0\n\u001b[32m    768\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dt > \u001b[32m60\u001b[39m:  \u001b[38;5;66;03m# If query took more than a minute\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rdfsolve-1/.venv/lib/python3.13/site-packages/SPARQLWrapper/Wrapper.py:960\u001b[39m, in \u001b[36mSPARQLWrapper.query\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mQueryResult\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    943\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[33;03m    Execute the query.\u001b[39;00m\n\u001b[32m    945\u001b[39m \u001b[33;03m    Exceptions can be raised if either the URI is wrong or the HTTP sends back an error (this is also the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    958\u001b[39m \u001b[33;03m    :rtype: :class:`QueryResult` instance\u001b[39;00m\n\u001b[32m    959\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rdfsolve-1/.venv/lib/python3.13/site-packages/SPARQLWrapper/Wrapper.py:924\u001b[39m, in \u001b[36mSPARQLWrapper._query\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.timeout:\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m         response = \u001b[43murlopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    926\u001b[39m         response = urlopener(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:189\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, context)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:489\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    486\u001b[39m     req = meth(req)\n\u001b[32m    488\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    492\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:506\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    505\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:466\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    465\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:1367\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:1323\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1321\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1322\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m-> \u001b[39m\u001b[32m1323\u001b[39m     r = \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1325\u001b[39m     h.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Generate fast VoID without count aggregations\n",
    "    \n",
    "    fast_void_graph = solver.void_generator(\n",
    "        graph_uri=graph_uri,\n",
    "        output_file=f\"{dataset_name}_void.ttl\",\n",
    "        counts=False  # Fast discovery without counts,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    print(f\"Graph contains {len(fast_void_graph)} triples\")\n",
    "    print(f\"Saved to: {dataset_name}_void.ttl\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f633f1",
   "metadata": {},
   "source": [
    "## Quick Dataset Structure Check\n",
    "\n",
    "Before running raw extraction, let's check if the dataset has the required structure (rdf:type relations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972bc359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset structure...\n",
      "Dataset has 1,165,797,810 rdf:type statements\n",
      "‚úì Dataset is compatible with raw extraction mode\n",
      "\n",
      "Sample triples from http://rdfportal.org/dataset/pdbj:\n",
      "  1. http://rdf.wwpdb.org/pdb/100D/atom_sites/100D... -> 22-rdf-syntax-ns#type -> http://rdf.wwpdb.org/schema/pdbx-v50.owl#atom_site...\n",
      "  2. http://rdf.wwpdb.org/pdb/300D/atom_sites/300D... -> 22-rdf-syntax-ns#type -> http://rdf.wwpdb.org/schema/pdbx-v50.owl#atom_site...\n",
      "  3. http://rdf.wwpdb.org/pdb/400D/atom_sites/400D... -> 22-rdf-syntax-ns#type -> http://rdf.wwpdb.org/schema/pdbx-v50.owl#atom_site...\n"
     ]
    }
   ],
   "source": [
    "# Quick check of dataset structure for raw extraction compatibility\n",
    "try:\n",
    "    from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "    \n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "    \n",
    "    # Test 1: Check if we have rdf:type relations\n",
    "    type_check_query = f\"\"\"\n",
    "    SELECT (COUNT(*) as ?count)\n",
    "    WHERE {{\n",
    "        GRAPH <{graph_uri}> {{\n",
    "            ?s a ?type .\n",
    "        }}\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    \n",
    "    sparql.setQuery(type_check_query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    print(\"Checking dataset structure...\")\n",
    "    results = sparql.query().convert()\n",
    "    type_count = int(results[\"results\"][\"bindings\"][0][\"count\"][\"value\"])\n",
    "    \n",
    "    print(f\"Dataset has {type_count:,} rdf:type statements\")\n",
    "    \n",
    "    if type_count > 0:\n",
    "        print(\"‚úì Dataset is compatible with raw extraction mode\")\n",
    "    else:\n",
    "        print(\"‚ö† Dataset may not be compatible with raw extraction\")\n",
    "        print(\"  (requires subjects to have rdf:type relations)\")\n",
    "    \n",
    "    # Test 2: Sample a few triples to see structure\n",
    "    sample_query = f\"\"\"\n",
    "    SELECT ?s ?p ?o\n",
    "    WHERE {{\n",
    "        GRAPH <{graph_uri}> {{\n",
    "            ?s ?p ?o .\n",
    "        }}\n",
    "    }}\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    \n",
    "    sparql.setQuery(sample_query)\n",
    "    print(f\"\\nSample triples from {graph_uri}:\")\n",
    "    \n",
    "    sample_results = sparql.query().convert()\n",
    "    for i, binding in enumerate(sample_results[\"results\"][\"bindings\"][:3]):\n",
    "        s = binding[\"s\"][\"value\"]\n",
    "        p = binding[\"p\"][\"value\"]\n",
    "        o = binding[\"o\"][\"value\"]\n",
    "        print(f\"  {i+1}. {s[:50]}... -> {p.split('/')[-1]} -> {o[:50]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Structure check failed: {e}\")\n",
    "    print(\"Proceeding anyway...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b47592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NEW raw extraction mode...\n",
      "üöÄ Starting VoID extraction from SPARQL endpoint\n",
      "üì° Endpoint: https://rdfportal.org/pdb/sparql\n",
      "üéØ Graph: http://rdfportal.org/dataset/pdbj\n",
      "‚ö° Mode: Raw extraction (Python post-processing)\n",
      "============================================================\n",
      "üîÑ Starting query: class_partitions\n",
      "‚úÖ Finished query: class_partitions (took 3.02s)\n",
      "üìä Parsing results for class_partitions...\n",
      "‚ö° Raw extraction: processing will be done in Python\n",
      "üîÑ Starting query: raw_triples\n",
      "‚úÖ Finished query: class_partitions (took 3.02s)\n",
      "üìä Parsing results for class_partitions...\n",
      "‚ö° Raw extraction: processing will be done in Python\n",
      "üîÑ Starting query: raw_triples\n",
      "‚ùå Query raw_triples failed after 1.38s: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b\"Virtuoso 37000 Error SP030: SPARQL compiler, line 37: syntax error at 'BIND' before '('\\n\\nSPARQL query:\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX void-ext: <http://ldf.fi/void-ext#>\\nCONSTRUCT {\\n    ?triple void-ext:subject ?subject ;\\n            void-ext:predicate ?predicate ;\\n            void-ext:object ?object ;\\n            void-ext:subjectType ?subject_type ;\\n            void-ext:objectType ?object_type ;\\n            void-ext:isLiteral ?is_literal .\\n}\\nWHERE {\\n    GRAPH <http://rdfportal.org/dataset/pdbj> {\\n        ?subject ?predicate ?object .\\n        \\n        # Get subject type (required)\\n        ?subject rdf:type ?subject_type .\\n        \\n        # Determine object characteristics\\n        BIND(isLiteral(?object) AS ?is_literal)\\n        \\n        # Get object type if it's a URI\\n        OPTIONAL {\\n            FILTER(isURI(?object))\\n            ?object rdf:type ?obj_type .\\n        }\\n        \\n        # Use placeholder for object type if no type found\\n        BIND(COALESCE(?obj_type, \\n                      IF(?is_literal, \\n                         <http://www.w3.org/2000/01/rdf-schema#Literal>,\\n                         <http://www.w3.org/2000/01/rdf-schema#Resource>)\\n            ) AS ?object_type)\\n    }\\n    \\n}\\n# Generate unique triple identifier\\nBIND(IRI(CONCAT('http://rdfportal.org/dataset/pdbj/void/triple_',\\n               MD5(CONCAT(STR(?subject), STR(?predicate), \\n                         STR(?object))))) AS ?triple)\"\n",
      "Raw extraction error: Failed to generate VoID from SPARQL endpoint: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b\"Virtuoso 37000 Error SP030: SPARQL compiler, line 37: syntax error at 'BIND' before '('\\n\\nSPARQL query:\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX void-ext: <http://ldf.fi/void-ext#>\\nCONSTRUCT {\\n    ?triple void-ext:subject ?subject ;\\n            void-ext:predicate ?predicate ;\\n            void-ext:object ?object ;\\n            void-ext:subjectType ?subject_type ;\\n            void-ext:objectType ?object_type ;\\n            void-ext:isLiteral ?is_literal .\\n}\\nWHERE {\\n    GRAPH <http://rdfportal.org/dataset/pdbj> {\\n        ?subject ?predicate ?object .\\n        \\n        # Get subject type (required)\\n        ?subject rdf:type ?subject_type .\\n        \\n        # Determine object characteristics\\n        BIND(isLiteral(?object) AS ?is_literal)\\n        \\n        # Get object type if it's a URI\\n        OPTIONAL {\\n            FILTER(isURI(?object))\\n            ?object rdf:type ?obj_type .\\n        }\\n        \\n        # Use placeholder for object type if no type found\\n        BIND(COALESCE(?obj_type, \\n                      IF(?is_literal, \\n                         <http://www.w3.org/2000/01/rdf-schema#Literal>,\\n                         <http://www.w3.org/2000/01/rdf-schema#Resource>)\\n            ) AS ?object_type)\\n    }\\n    \\n}\\n# Generate unique triple identifier\\nBIND(IRI(CONCAT('http://rdfportal.org/dataset/pdbj/void/triple_',\\n               MD5(CONCAT(STR(?subject), STR(?predicate), \\n                         STR(?object))))) AS ?triple)\"\n",
      "‚ùå Query raw_triples failed after 1.38s: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b\"Virtuoso 37000 Error SP030: SPARQL compiler, line 37: syntax error at 'BIND' before '('\\n\\nSPARQL query:\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX void-ext: <http://ldf.fi/void-ext#>\\nCONSTRUCT {\\n    ?triple void-ext:subject ?subject ;\\n            void-ext:predicate ?predicate ;\\n            void-ext:object ?object ;\\n            void-ext:subjectType ?subject_type ;\\n            void-ext:objectType ?object_type ;\\n            void-ext:isLiteral ?is_literal .\\n}\\nWHERE {\\n    GRAPH <http://rdfportal.org/dataset/pdbj> {\\n        ?subject ?predicate ?object .\\n        \\n        # Get subject type (required)\\n        ?subject rdf:type ?subject_type .\\n        \\n        # Determine object characteristics\\n        BIND(isLiteral(?object) AS ?is_literal)\\n        \\n        # Get object type if it's a URI\\n        OPTIONAL {\\n            FILTER(isURI(?object))\\n            ?object rdf:type ?obj_type .\\n        }\\n        \\n        # Use placeholder for object type if no type found\\n        BIND(COALESCE(?obj_type, \\n                      IF(?is_literal, \\n                         <http://www.w3.org/2000/01/rdf-schema#Literal>,\\n                         <http://www.w3.org/2000/01/rdf-schema#Resource>)\\n            ) AS ?object_type)\\n    }\\n    \\n}\\n# Generate unique triple identifier\\nBIND(IRI(CONCAT('http://rdfportal.org/dataset/pdbj/void/triple_',\\n               MD5(CONCAT(STR(?subject), STR(?predicate), \\n                         STR(?object))))) AS ?triple)\"\n",
      "Raw extraction error: Failed to generate VoID from SPARQL endpoint: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b\"Virtuoso 37000 Error SP030: SPARQL compiler, line 37: syntax error at 'BIND' before '('\\n\\nSPARQL query:\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX void-ext: <http://ldf.fi/void-ext#>\\nCONSTRUCT {\\n    ?triple void-ext:subject ?subject ;\\n            void-ext:predicate ?predicate ;\\n            void-ext:object ?object ;\\n            void-ext:subjectType ?subject_type ;\\n            void-ext:objectType ?object_type ;\\n            void-ext:isLiteral ?is_literal .\\n}\\nWHERE {\\n    GRAPH <http://rdfportal.org/dataset/pdbj> {\\n        ?subject ?predicate ?object .\\n        \\n        # Get subject type (required)\\n        ?subject rdf:type ?subject_type .\\n        \\n        # Determine object characteristics\\n        BIND(isLiteral(?object) AS ?is_literal)\\n        \\n        # Get object type if it's a URI\\n        OPTIONAL {\\n            FILTER(isURI(?object))\\n            ?object rdf:type ?obj_type .\\n        }\\n        \\n        # Use placeholder for object type if no type found\\n        BIND(COALESCE(?obj_type, \\n                      IF(?is_literal, \\n                         <http://www.w3.org/2000/01/rdf-schema#Literal>,\\n                         <http://www.w3.org/2000/01/rdf-schema#Resource>)\\n            ) AS ?object_type)\\n    }\\n    \\n}\\n# Generate unique triple identifier\\nBIND(IRI(CONCAT('http://rdfportal.org/dataset/pdbj/void/triple_',\\n               MD5(CONCAT(STR(?subject), STR(?predicate), \\n                         STR(?object))))) AS ?triple)\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/javi/rdfsolve-1/.venv/lib/python3.13/site-packages/SPARQLWrapper/Wrapper.py\", line 924, in _query\n",
      "    response = urlopener(request, timeout=self.timeout)\n",
      "  File \"/home/javi/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py\", line 189, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/javi/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py\", line 495, in open\n",
      "    response = meth(req, response)\n",
      "  File \"/home/javi/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py\", line 604, in http_response\n",
      "    response = self.parent.error(\n",
      "        'http', request, response, code, msg, hdrs)\n",
      "  File \"/home/javi/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py\", line 533, in error\n",
      "    return self._call_chain(*args)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/home/javi/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py\", line 466, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/home/javi/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py\", line 613, in http_error_default\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 400: Bad Request\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/javi/rdfsolve-1/src/rdfsolve/void_parser.py\", line 847, in generate_void_from_sparql\n",
      "    query_count += 1\n",
      "  File \"/home/javi/rdfsolve-1/src/rdfsolve/void_parser.py\", line 765, in run_construct\n",
      "    results = sparql.query().convert()\n",
      "              ~~~~~~~~~~~~^^\n",
      "  File \"/home/javi/rdfsolve-1/.venv/lib/python3.13/site-packages/SPARQLWrapper/Wrapper.py\", line 960, in query\n",
      "    return QueryResult(self._query())\n",
      "                       ~~~~~~~~~~~^^\n",
      "  File \"/home/javi/rdfsolve-1/.venv/lib/python3.13/site-packages/SPARQLWrapper/Wrapper.py\", line 930, in _query\n",
      "    raise QueryBadFormed(e.read())\n",
      "SPARQLWrapper.SPARQLExceptions.QueryBadFormed: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b\"Virtuoso 37000 Error SP030: SPARQL compiler, line 37: syntax error at 'BIND' before '('\\n\\nSPARQL query:\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX void-ext: <http://ldf.fi/void-ext#>\\nCONSTRUCT {\\n    ?triple void-ext:subject ?subject ;\\n            void-ext:predicate ?predicate ;\\n            void-ext:object ?object ;\\n            void-ext:subjectType ?subject_type ;\\n            void-ext:objectType ?object_type ;\\n            void-ext:isLiteral ?is_literal .\\n}\\nWHERE {\\n    GRAPH <http://rdfportal.org/dataset/pdbj> {\\n        ?subject ?predicate ?object .\\n        \\n        # Get subject type (required)\\n        ?subject rdf:type ?subject_type .\\n        \\n        # Determine object characteristics\\n        BIND(isLiteral(?object) AS ?is_literal)\\n        \\n        # Get object type if it's a URI\\n        OPTIONAL {\\n            FILTER(isURI(?object))\\n            ?object rdf:type ?obj_type .\\n        }\\n        \\n        # Use placeholder for object type if no type found\\n        BIND(COALESCE(?obj_type, \\n                      IF(?is_literal, \\n                         <http://www.w3.org/2000/01/rdf-schema#Literal>,\\n                         <http://www.w3.org/2000/01/rdf-schema#Resource>)\\n            ) AS ?object_type)\\n    }\\n    \\n}\\n# Generate unique triple identifier\\nBIND(IRI(CONCAT('http://rdfportal.org/dataset/pdbj/void/triple_',\\n               MD5(CONCAT(STR(?subject), STR(?predicate), \\n                         STR(?object))))) AS ?triple)\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_848979/1929136267.py\", line 5, in <module>\n",
      "    raw_parser = VoidParser.from_sparql(\n",
      "        endpoint_url=endpoint_url,\n",
      "    ...<3 lines>...\n",
      "        preserve_values=True      # NEW: Preserve actual values (not just Resource/Literal)\n",
      "    )\n",
      "  File \"/home/javi/rdfsolve-1/src/rdfsolve/void_parser.py\", line 908, in from_sparql\n",
      "    \"\"\"\n",
      "    \n",
      "    void_graph = cls.generate_void_from_sparql(\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        endpoint_url, graph_uri, output_file, raw_extraction=raw_extraction\n",
      "    \n",
      "  File \"/home/javi/rdfsolve-1/src/rdfsolve/void_parser.py\", line 886, in generate_void_from_sparql\n",
      "    except Exception as e:\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "        raise RuntimeError(\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "            f\"Failed to generate VoID from SPARQL endpoint: {e}\"\n",
      "    \n",
      "RuntimeError: Failed to generate VoID from SPARQL endpoint: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b\"Virtuoso 37000 Error SP030: SPARQL compiler, line 37: syntax error at 'BIND' before '('\\n\\nSPARQL query:\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX void-ext: <http://ldf.fi/void-ext#>\\nCONSTRUCT {\\n    ?triple void-ext:subject ?subject ;\\n            void-ext:predicate ?predicate ;\\n            void-ext:object ?object ;\\n            void-ext:subjectType ?subject_type ;\\n            void-ext:objectType ?object_type ;\\n            void-ext:isLiteral ?is_literal .\\n}\\nWHERE {\\n    GRAPH <http://rdfportal.org/dataset/pdbj> {\\n        ?subject ?predicate ?object .\\n        \\n        # Get subject type (required)\\n        ?subject rdf:type ?subject_type .\\n        \\n        # Determine object characteristics\\n        BIND(isLiteral(?object) AS ?is_literal)\\n        \\n        # Get object type if it's a URI\\n        OPTIONAL {\\n            FILTER(isURI(?object))\\n            ?object rdf:type ?obj_type .\\n        }\\n        \\n        # Use placeholder for object type if no type found\\n        BIND(COALESCE(?obj_type, \\n                      IF(?is_literal, \\n                         <http://www.w3.org/2000/01/rdf-schema#Literal>,\\n                         <http://www.w3.org/2000/01/rdf-schema#Resource>)\\n            ) AS ?object_type)\\n    }\\n    \\n}\\n# Generate unique triple identifier\\nBIND(IRI(CONCAT('http://rdfportal.org/dataset/pdbj/void/triple_',\\n               MD5(CONCAT(STR(?subject), STR(?predicate), \\n                         STR(?object))))) AS ?triple)\"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Using NEW raw extraction mode...\")\n",
    "    \n",
    "    # Use VoidParser.from_sparql with raw_extraction=True\n",
    "    print(\"Note: Raw extraction requires subjects to have rdf:type relations\")\n",
    "    print(\"Attempting raw extraction...\")\n",
    "    \n",
    "    raw_parser = VoidParser.from_sparql(\n",
    "        endpoint_url=endpoint_url,\n",
    "        graph_uri=graph_uri,\n",
    "        output_file=f\"{dataset_name}_raw_void.ttl\",\n",
    "        raw_extraction=True,      # NEW: Enable raw extraction\n",
    "        preserve_values=True      # NEW: Preserve actual values (not just Resource/Literal)\n",
    "    )\n",
    "    \n",
    "    print(\"Raw extraction VoID completed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Raw extraction error: {e}\")\n",
    "    print(\"\\nThis might happen if:\")\n",
    "    print(\"1. The SPARQL endpoint doesn't support some query features\")\n",
    "    print(\"2. The dataset doesn't have rdf:type relations for subjects\")\n",
    "    print(\"3. There are SPARQL syntax compatibility issues\")\n",
    "    print(\"\\nTrying fallback to traditional mode...\")\n",
    "    \n",
    "    try:\n",
    "        # Fallback to traditional mode\n",
    "        raw_parser = VoidParser.from_sparql(\n",
    "            endpoint_url=endpoint_url,\n",
    "            graph_uri=graph_uri,\n",
    "            output_file=f\"{dataset_name}_traditional_void.ttl\",\n",
    "            raw_extraction=False     # Traditional mode\n",
    "        )\n",
    "        print(\"Fallback to traditional mode succeeded!\")\n",
    "        \n",
    "    except Exception as fallback_error:\n",
    "        print(f\"Fallback also failed: {fallback_error}\")\n",
    "        raw_parser = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7546dbf9",
   "metadata": {},
   "source": [
    "## Alternative: Simplified Raw Extraction\n",
    "\n",
    "If the standard raw extraction fails, we can try a simplified approach that doesn't require all subjects to have rdf:type relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e95c446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying simplified raw extraction approach...\n",
      "Executing simplified extraction query...\n",
      "Simplified extraction successful! Got 5000 triples\n",
      "Post-processed 1000 raw triples into 1 schema triples\n",
      "Found 1 unique properties\n",
      "Preserved values: True\n",
      "Simplified raw extraction completed!\n"
     ]
    }
   ],
   "source": [
    "# If the standard raw extraction failed, try a simplified approach\n",
    "# This creates a custom simplified raw extraction query\n",
    "\n",
    "try:\n",
    "    print(\"Trying simplified raw extraction approach...\")\n",
    "    \n",
    "    # Create a simplified query manually\n",
    "    from SPARQLWrapper import SPARQLWrapper, TURTLE\n",
    "    from rdflib import Graph\n",
    "    \n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "    sparql.setReturnFormat(TURTLE)\n",
    "    \n",
    "    # Simple query to get some triples with basic type info\n",
    "    simple_query = f\"\"\"\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    PREFIX void-ext: <http://ldf.fi/void-ext#>\n",
    "    CONSTRUCT {{\n",
    "        ?triple void-ext:subject ?subject ;\n",
    "                void-ext:predicate ?predicate ;\n",
    "                void-ext:object ?object ;\n",
    "                void-ext:subjectType \"Resource\" ;\n",
    "                void-ext:objectType ?object_type .\n",
    "    }}\n",
    "    WHERE {{\n",
    "        GRAPH <{graph_uri}> {{\n",
    "            ?subject ?predicate ?object .\n",
    "            \n",
    "            BIND(IF(isLiteral(?object), \"Literal\", \"Resource\") AS ?object_type)\n",
    "            \n",
    "            # Generate unique triple identifier  \n",
    "            BIND(IRI(CONCAT('{graph_uri}/void/triple_',\n",
    "                           MD5(CONCAT(STR(?subject), STR(?predicate), STR(?object))))) AS ?triple)\n",
    "        }}\n",
    "    }}\n",
    "    LIMIT 1000\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Executing simplified extraction query...\")\n",
    "    sparql.setQuery(simple_query)\n",
    "    \n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    # Create VoID graph and parser\n",
    "    if results:\n",
    "        void_graph = Graph()\n",
    "        if isinstance(results, bytes):\n",
    "            void_graph.parse(data=results.decode('utf-8'), format=\"turtle\")\n",
    "        else:\n",
    "            void_graph.parse(data=str(results), format=\"turtle\")\n",
    "        \n",
    "        print(f\"Simplified extraction successful! Got {len(void_graph)} triples\")\n",
    "        \n",
    "        # Create parser from the simplified data\n",
    "        simple_parser = VoidParser(void_graph)\n",
    "        simple_parser._process_raw_triples(preserve_values=True)\n",
    "        \n",
    "        print(\"Simplified raw extraction completed!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No results from simplified query\")\n",
    "        simple_parser = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Simplified extraction also failed: {e}\")\n",
    "    simple_parser = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351670d",
   "metadata": {},
   "source": [
    "## Step 3c: Extract Schema from Raw Extraction Mode\n",
    "\n",
    "The raw extraction preserves actual values instead of just classifying them as \"Resource\" or \"Literal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd54a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Extracting schema from raw extraction...\")\n",
    "    \n",
    "    # Get schema as DataFrame (with preserved values!)\n",
    "    raw_schema_df = raw_parser.to_schema(filter_void_nodes=True)\n",
    "    \n",
    "    print(\"Raw extraction schema completed\")\n",
    "    print(f\"Total schema triples: {len(raw_schema_df)}\")\n",
    "    print(f\"Unique classes: {raw_schema_df['subject_class'].nunique()}\")\n",
    "    print(f\"Unique properties: {raw_schema_df['property'].nunique()}\")\n",
    "    \n",
    "    # Compare value preservation\n",
    "    print(f\"\\nValue preservation comparison:\")\n",
    "    print(f\"Traditional mode object classes: Resource, Literal\")\n",
    "    print(f\"Raw mode unique objects: {raw_schema_df['object_class'].nunique()}\")\n",
    "    \n",
    "    # Show sample of preserved values\n",
    "    print(f\"\\nSample preserved object values:\")\n",
    "    unique_objects = raw_schema_df['object_class'].unique()\n",
    "    for obj in unique_objects[:10]:\n",
    "        if obj not in ['Resource', 'Literal']:\n",
    "            print(f\"  - {obj}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Raw schema extraction failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e902255d",
   "metadata": {},
   "source": [
    "## Step 3d: Compare Traditional vs Raw Extraction\n",
    "\n",
    "See the difference in data preservation between the two modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6056799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two approaches if both were successful\n",
    "if 'fast_schema_df' in globals() and 'raw_schema_df' in globals():\n",
    "    print(\"COMPARISON: Traditional vs Raw Extraction\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"Traditional mode:\")\n",
    "    print(f\"  - Schema triples: {len(fast_schema_df):,}\")\n",
    "    print(f\"  - Unique objects: {fast_schema_df['object_class'].nunique()}\")\n",
    "    print(f\"  - Object types: {set(fast_schema_df['object_class'].unique())}\")\n",
    "    \n",
    "    print(f\"\\nRaw extraction mode:\")\n",
    "    print(f\"  - Schema triples: {len(raw_schema_df):,}\")  \n",
    "    print(f\"  - Unique objects: {raw_schema_df['object_class'].nunique()}\")\n",
    "    print(f\"  - Sample objects: {list(raw_schema_df['object_class'].unique())[:5]}...\")\n",
    "    \n",
    "    # Show side-by-side comparison for same property\n",
    "    print(f\"\\nSide-by-side comparison (same property):\")\n",
    "    if len(fast_schema_df) > 0 and len(raw_schema_df) > 0:\n",
    "        # Find a common property\n",
    "        common_props = set(fast_schema_df['property'].unique()) & set(raw_schema_df['property'].unique())\n",
    "        if common_props:\n",
    "            prop = list(common_props)[0]\n",
    "            print(f\"Property: {prop}\")\n",
    "            \n",
    "            fast_objects = set(fast_schema_df[fast_schema_df['property'] == prop]['object_class'].unique())\n",
    "            raw_objects = set(raw_schema_df[raw_schema_df['property'] == prop]['object_class'].unique())\n",
    "            \n",
    "            print(f\"  Traditional: {fast_objects}\")\n",
    "            print(f\"  Raw mode:    {list(raw_objects)[:3]}...\")\n",
    "            \n",
    "else:\n",
    "    print(\"Run both traditional and raw extraction modes to compare\")\n",
    "\n",
    "# Display sample from raw extraction\n",
    "if 'raw_schema_df' in globals():\n",
    "    print(f\"\\nSample from raw extraction (preserves actual values):\")\n",
    "    display(raw_schema_df[~raw_schema_df.object_class.isin([\"Class\", \"Resource\", \"Literal\"])].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ede676",
   "metadata": {},
   "source": [
    "## Alternative: Raw Extraction with Traditional Classification\n",
    "\n",
    "You can also use raw extraction for performance benefits while still classifying values as Resource/Literal for traditional VoID compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ecd685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Raw extraction with traditional VoID classification\n",
    "# This gives you performance benefits while maintaining VoID compatibility\n",
    "\n",
    "try:\n",
    "    print(\"Raw extraction with traditional classification...\")\n",
    "    \n",
    "    # Raw extraction but with preserve_values=False for traditional classification\n",
    "    classified_parser = VoidParser.from_sparql(\n",
    "        endpoint_url=endpoint_url,\n",
    "        graph_uri=graph_uri,\n",
    "        raw_extraction=True,      # Fast extraction\n",
    "        preserve_values=False     # Traditional Resource/Literal classification\n",
    "    )\n",
    "    \n",
    "    classified_schema = classified_parser.to_schema(filter_void_nodes=True)\n",
    "    \n",
    "    print(f\"Fast extraction + traditional classification:\")\n",
    "    print(f\"  - Schema triples: {len(classified_schema):,}\")\n",
    "    print(f\"  - Object types: {set(classified_schema['object_class'].unique())}\")\n",
    "    print(f\"  - Performance: Fast (raw extraction)\")\n",
    "    print(f\"  - Compatibility: Full VoID compatibility\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Classified raw extraction error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4e47d",
   "metadata": {},
   "source": [
    "## Step 4: Extract Schema from Fast VoID\n",
    "\n",
    "Extract schema structure from the fast-generated VoID description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26688cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting schema from fast VoID...\n",
      "Fast schema extraction failed: name 'fast_void_graph' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Extracting schema from fast VoID...\")\n",
    "    fast_parser = VoidParser(fast_void_graph)\n",
    "    \n",
    "    # Get schema as DataFrame\n",
    "    fast_schema_df = fast_parser.to_schema(filter_void_nodes=True)\n",
    "    \n",
    "    print(\"Fast schema extraction completed\")\n",
    "    print(f\"Total schema triples: {len(fast_schema_df)}\")\n",
    "    print(f\"Unique classes: {fast_schema_df['subject_class'].nunique()}\")\n",
    "    print(f\"Unique properties: {fast_schema_df['property'].nunique()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fast schema extraction failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed4057",
   "metadata": {},
   "source": [
    "## Step 5: Schema Visualization\n",
    "\n",
    "Display a sample of the extracted schema from fast discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085e7e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fast_schema_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Show sample of the fast schema (excluding generic classes)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m display(\u001b[43mfast_schema_df\u001b[49m[~fast_schema_df.object_class.isin([\u001b[33m\"\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mResource\u001b[39m\u001b[33m\"\u001b[39m])].head(\u001b[32m10\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'fast_schema_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Show sample of the fast schema (excluding generic classes)\n",
    "display(fast_schema_df[~fast_schema_df.object_class.isin([\"Class\", \"Resource\"])].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f5f39",
   "metadata": {},
   "source": [
    "## Step 6: Analyze AOP Wiki RDF Key Event\n",
    "\n",
    "Examine the `KeyEvent` class as an example of detailed analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DirectedInteraction Analysis (Complete Mode):\n",
      "Properties found: 35\n",
      "\n",
      "KeyEvent Properties:\n",
      "  PATO_0001241         -> GO_0008150\n",
      "  PATO_0001241         -> Literal\n",
      "  PATO_0001241         -> PATO_0001241\n",
      "  PATO_0001241         -> OrganContext\n",
      "  PATO_0001241         -> CellTypeContext\n",
      "  label                -> Literal\n",
      "  identifier           -> KeyEvent\n",
      "  source               -> Literal\n",
      "  PATO_0000047         -> Literal\n",
      "  title                -> Literal\n",
      "  alternative          -> Literal\n",
      "  isPartOf             -> AdverseOutcomePathway\n",
      "  CellTypeContext      -> PATO_0001241\n",
      "  CellTypeContext      -> CellTypeContext\n",
      "  CellTypeContext      -> OrganContext\n",
      "\n",
      "No bdb* properties found in KeyEvent\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Focus on DirectedInteraction class\n",
    "    di_schema = fast_schema_df[fast_schema_df[\"subject_class\"] == \"KeyEvent\"]\n",
    "\n",
    "    print(f\"DirectedInteraction Analysis (Complete Mode):\")\n",
    "    print(f\"Properties found: {len(di_schema)}\")\n",
    "\n",
    "    if len(di_schema) > 0:\n",
    "        print(f\"\\nKeyEvent Properties:\")\n",
    "        for _, row in di_schema.head(15).iterrows():\n",
    "            print(f\"  {row['property']:20} -> {row['object_class']}\")\n",
    "\n",
    "        # Look for database cross-references (bdb*)\n",
    "        bdb_props = di_schema[di_schema[\"property\"].str.contains(\"bdb\", na=False)]\n",
    "        if len(bdb_props) > 0:\n",
    "            print(f\"\\nDatabase Cross-References (bdb*):\")\n",
    "            print(f\"Found {len(bdb_props)} bdb properties\")\n",
    "            for _, row in bdb_props.iterrows():\n",
    "                print(f\"  {row['property']:15} -> {row['object_class']}\")\n",
    "        else:\n",
    "            print(\"\\nNo bdb* properties found in KeyEvent\")\n",
    "    else:\n",
    "        print(\"\\nKeyEvent class not found in schema\")\n",
    "        print(\"Available classes:\")\n",
    "        for cls in fast_schema_df[\"subject_class\"].unique()[:10]:\n",
    "            print(f\"  - {cls}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"KeyEvent analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674c701",
   "metadata": {},
   "source": [
    "## Step 7: Export Fast Discovery Results\n",
    "\n",
    "Export the fast discovery schema as JSON and CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f7999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating JSON schema (fast discovery)...\n",
      "Fast JSON export completed\n",
      "Total triples: 240\n",
      "Classes: 26\n",
      "Properties: 65\n",
      "Object types: 28\n",
      "\n",
      "Fast JSON schema saved to: aopwikirdf_complete_schema.json\n",
      "Fast CSV schema saved to: aopwikirdf_complete_schema.csv\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Export as JSON\n",
    "    print(\"Generating JSON schema (fast discovery)...\")\n",
    "    fast_schema_json = fast_parser.to_json(filter_void_nodes=True)\n",
    "    \n",
    "    print(\"Fast JSON export completed\")\n",
    "    print(f\"Total triples: {fast_schema_json['metadata']['total_triples']}\")\n",
    "    print(f\"Classes: {len(fast_schema_json['metadata']['classes'])}\")\n",
    "    print(f\"Properties: {len(fast_schema_json['metadata']['properties'])}\")\n",
    "    print(f\"Object types: {len(fast_schema_json['metadata']['objects'])}\")\n",
    "    \n",
    "    # Save JSON to file\n",
    "    import json\n",
    "    with open(f\"{dataset_name}_schema.json\", \"w\") as f:\n",
    "        json.dump(fast_schema_json, f, indent=2)\n",
    "    print(f\"\\nFast JSON schema saved to: {dataset_name}_schema.json\")\n",
    "    \n",
    "    # Export as CSV\n",
    "    fast_schema_df.to_csv(f\"{dataset_name}_schema.csv\", index=False)\n",
    "    print(f\"Fast CSV schema saved to: {dataset_name}_schema.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fast export failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8153b673",
   "metadata": {},
   "source": [
    "## Optional: Sample Limiting for Very Large Datasets\n",
    "\n",
    "For extremely large datasets, you can add a sample limit for even faster discovery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Ultra-fast discovery with sample limit\n",
    "# Uncomment to try with a sample of 1000 triples for very fast exploration\n",
    "\n",
    "# try:\n",
    "#     print(\"Ultra-fast discovery with sampling...\")\n",
    "#     \n",
    "#     sampled_void_graph = solver.void_generator(\n",
    "#         graph_uri=graph_uri,\n",
    "#         output_file=f\"{dataset_name}_sampled_void.ttl\",\n",
    "#         counts=False,\n",
    "#         sample_limit=1000  # Only sample 1000 triples\n",
    "#     )\n",
    "#     \n",
    "#     print(f\"Sampled VoID contains {len(sampled_void_graph)} triples\")\n",
    "#     \n",
    "# except Exception as e:\n",
    "#     print(f\"Sampled mode error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566e6e4",
   "metadata": {},
   "source": [
    "## JSON-LD Export\n",
    "\n",
    "Export the VoID description and schema as JSON-LD with automatic prefix extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export AOP-Wiki RDF (Fast) data as JSON-LD (automatic prefix extraction)\n",
    "print(\"Exporting AOP-Wiki RDF (Fast) VoID and Schema as JSON-LD...\")\n",
    "\n",
    "# Export complete VoID with automatic context\n",
    "void_jsonld = solver.export_void_jsonld(\n",
    "    output_file=\"aopwikirdf_fast_void.jsonld\",\n",
    "    indent=2\n",
    ")\n",
    "\n",
    "# Export schema only with automatic context\n",
    "schema_jsonld = solver.export_schema_jsonld(\n",
    "    output_file=\"aopwikirdf_fast_schema.jsonld\",\n",
    "    indent=2,\n",
    "    filter_void_nodes=True\n",
    ")\n",
    "\n",
    "print(f\"Exported files:\")\n",
    "print(f\"  - aopwikirdf_fast_void.jsonld ({len(void_jsonld)} chars)\")\n",
    "print(f\"  - aopwikirdf_fast_schema.jsonld ({len(schema_jsonld)} chars)\")\n",
    "\n",
    "# Show automatically extracted prefixes\n",
    "prefixes = solver._extract_prefixes_from_void()\n",
    "print(f\"\\nAuto-extracted prefixes: {', '.join(sorted(prefixes.keys()))}\")\n",
    "\n",
    "print(f\"\\nSchema Preview:\")\n",
    "print(schema_jsonld[:300] + \"...\" if len(schema_jsonld) > 300 else schema_jsonld)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdfsolve-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
