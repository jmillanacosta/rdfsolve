{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f8db7e",
   "metadata": {},
   "source": [
    "# RDFSolve: PubChem MeSH - Complete Analysis\n",
    "\n",
    "This notebook demonstrates VoID generation with full count aggregations:\n",
    "1. Setting up an endpoint and graph\n",
    "2. Generating comprehensive VoID descriptions using CONSTRUCT queries with COUNT aggregations\n",
    "3. Extracting detailed schema from the VoID description\n",
    "4. Analyzing the results as DataFrame and JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f9f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdfsolve.rdfsolve import RDFSolver\n",
    "from rdfsolve.void_parser import VoidParser, generate_void_from_endpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b11a86",
   "metadata": {},
   "source": [
    "## Step 1: Configure Dataset Parameters\n",
    "\n",
    "We'll configure the PubChem MeSH dataset with its SPARQL endpoint and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed94598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mesh_headers\n",
      "Endpoint: https://idsm.elixir-czech.cz/sparql/endpoint/idsm\n",
      "VoID IRI: http://id.nlm.nih.gov/mesh/heading\n",
      "Graph URI: http://id.nlm.nih.gov/mesh/heading\n",
      "Mode: Complete (with COUNT aggregations)\n"
     ]
    }
   ],
   "source": [
    "# MeSH configuration\n",
    "endpoint_url = \"https://idsm.elixir-czech.cz/sparql/endpoint/idsm\"\n",
    "dataset_name = \"mesh_headers\"\n",
    "void_iri = \"http://id.nlm.nih.gov/mesh/heading\"\n",
    "graph_uri = \"http://id.nlm.nih.gov/mesh/heading\"  # Specify the correct graph URI\n",
    "working_path = \".\"\n",
    "\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Endpoint: {endpoint_url}\")\n",
    "print(f\"VoID IRI: {void_iri}\")\n",
    "print(f\"Graph URI: {graph_uri}\")\n",
    "print(f\"Mode: Complete (with COUNT aggregations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d00bb37",
   "metadata": {},
   "source": [
    "## Step 2: Initialize RDFSolver\n",
    "\n",
    "Create an RDFSolver instance with our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb6d19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDFSolver initialized successfully\n",
      "Endpoint: https://idsm.elixir-czech.cz/sparql/endpoint/idsm\n",
      "Dataset: mesh_headers\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize RDFSolver with our configuration\n",
    "    solver = RDFSolver(\n",
    "        endpoint=endpoint_url,\n",
    "        path=working_path,\n",
    "        void_iri=void_iri,\n",
    "        dataset_name=dataset_name\n",
    "    )\n",
    "    \n",
    "    print(\"RDFSolver initialized successfully\")\n",
    "    print(f\"Endpoint: {solver.endpoint}\")\n",
    "    print(f\"Dataset: {solver.dataset_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba595c4",
   "metadata": {},
   "source": [
    "## Step 3: Generate Complete VoID Description\n",
    "\n",
    "Generate VoID with full COUNT aggregations. This provides complete statistics but takes longer to execute.\n",
    "\n",
    "Three CONSTRUCT queries get the partitions for classes, properties, and datatypes from the specified graph with complete count information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b73853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating VoID from endpoint: https://idsm.elixir-czech.cz/sparql/endpoint/idsm\n",
      "Using graph URI: http://id.nlm.nih.gov/mesh/heading\n",
      "Starting query: class_partitions\n",
      "Finished query: class_partitions (took 0.87s)\n",
      "Starting query: property_partitions\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Generate VoID using CONSTRUCT query approach with full counts\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     void_graph = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvoid_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgraph_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_void.ttl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Full count aggregations\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGraph contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(void_graph)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m triples\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_void.ttl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rdfsolve-1/src/rdfsolve/rdfsolve.py:165\u001b[39m, in \u001b[36mRDFSolver.void_generator\u001b[39m\u001b[34m(self, graph_uri, output_file, counts, sample_limit)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_limit:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing sample limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_limit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m void_graph = \u001b[43mVoidParser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_void_from_sparql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_endpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_limit\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m._void = void_graph\n\u001b[32m    170\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mVoID generation completed successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rdfsolve-1/src/rdfsolve/void_parser.py:773\u001b[39m, in \u001b[36mgenerate_void_from_sparql\u001b[39m\u001b[34m(endpoint_url, graph_uri, output_file, counts, sample_limit, raw_extraction)\u001b[39m\n\u001b[32m    770\u001b[39m     seconds = int(dt % 60)\n\u001b[32m    771\u001b[39m     print(f\"✅ Finished query: {name} \"\n\u001b[32m    772\u001b[39m           f\"(took {minutes}m {seconds}s)\")\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m else:\n\u001b[32m    774\u001b[39m     print(f\"✅ Finished query: {name} (took {dt:.2f}s)\")\n\u001b[32m    776\u001b[39m # Parse result - handle bytes properly\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rdfsolve-1/src/rdfsolve/void_parser.py:722\u001b[39m, in \u001b[36mrun_construct\u001b[39m\u001b[34m(query_text, name, is_optional)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    707\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_void_from_sparql\u001b[39m(endpoint_url: \u001b[38;5;28mstr\u001b[39m, graph_uri: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    708\u001b[39m                               output_file: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    709\u001b[39m                               counts: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    710\u001b[39m                               sample_limit: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    711\u001b[39m                               raw_extraction: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> Graph:\n\u001b[32m    712\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    713\u001b[39m \u001b[33;03m    Generate VoID description from SPARQL endpoint using CONSTRUCT queries.\u001b[39;00m\n\u001b[32m    714\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    715\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    716\u001b[39m \u001b[33;03m        endpoint_url: SPARQL endpoint URL\u001b[39;00m\n\u001b[32m    717\u001b[39m \u001b[33;03m        graph_uri: Graph URI for the dataset\u001b[39;00m\n\u001b[32m    718\u001b[39m \u001b[33;03m        output_file: Optional output file path for TTL\u001b[39;00m\n\u001b[32m    719\u001b[39m \u001b[33;03m        counts: If True, include COUNT aggregations; faster if False\u001b[39;00m\n\u001b[32m    720\u001b[39m \u001b[33;03m        sample_limit: Optional LIMIT for sampling (speeds up discovery)\u001b[39;00m\n\u001b[32m    721\u001b[39m \u001b[33;03m        raw_extraction: If True, extract raw triples for post-processing\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m \u001b[33;03m        \u001b[39;00m\n\u001b[32m    723\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    724\u001b[39m \u001b[33;03m        RDF Graph containing the VoID description\u001b[39;00m\n\u001b[32m    725\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    726\u001b[39m     queries = VoidParser.get_void_queries(graph_uri, counts, sample_limit, \n\u001b[32m    727\u001b[39m                                           raw_extraction)\n\u001b[32m    729\u001b[39m     sparql = SPARQLWrapper(endpoint_url)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rdfsolve-1/.venv/lib/python3.13/site-packages/SPARQLWrapper/Wrapper.py:960\u001b[39m, in \u001b[36mSPARQLWrapper.query\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mQueryResult\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    943\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[33;03m    Execute the query.\u001b[39;00m\n\u001b[32m    945\u001b[39m \u001b[33;03m    Exceptions can be raised if either the URI is wrong or the HTTP sends back an error (this is also the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    958\u001b[39m \u001b[33;03m    :rtype: :class:`QueryResult` instance\u001b[39;00m\n\u001b[32m    959\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rdfsolve-1/.venv/lib/python3.13/site-packages/SPARQLWrapper/Wrapper.py:924\u001b[39m, in \u001b[36mSPARQLWrapper._query\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.timeout:\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m         response = \u001b[43murlopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    926\u001b[39m         response = urlopener(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:189\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, context)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:489\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    486\u001b[39m     req = meth(req)\n\u001b[32m    488\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    492\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:506\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    505\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:466\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    465\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:1367\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/urllib/request.py:1323\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1321\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1322\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m-> \u001b[39m\u001b[32m1323\u001b[39m     r = \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1325\u001b[39m     h.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    # Generate VoID using CONSTRUCT query approach with full counts\n",
    "\n",
    "    void_graph = solver.void_generator(\n",
    "        graph_uri=graph_uri,\n",
    "        output_file=f\"{dataset_name}_void.ttl\",\n",
    "        counts=True  # Full count aggregations\n",
    "    )\n",
    "    \n",
    "    print(f\"Graph contains {len(void_graph)} triples\")\n",
    "    print(f\"Saved to: {dataset_name}_void.ttl\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a46d4b2",
   "metadata": {},
   "source": [
    "## Step 4: Extract Schema from Complete VoID\n",
    "\n",
    "`VoidParser` via `solver.extract_schema()` extracts the comprehensive schema structure from the generated VoID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df6764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema extraction failed: No VoID description available. Run void_generator() first.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Extract schema\n",
    "    parser = solver.extract_schema()\n",
    "\n",
    "    # Get schema as DataFrame\n",
    "    print(\"Extracting complete schema as DataFrame...\")\n",
    "    schema_df = parser.to_schema(filter_void_nodes=True)\n",
    "\n",
    "    print(\"Complete schema extraction completed\")\n",
    "    print(f\"Total schema triples: {len(schema_df)}\")\n",
    "    print(f\"Unique classes: {schema_df['subject_class'].nunique()}\")\n",
    "    print(f\"Unique properties: {schema_df['property'].nunique()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Schema extraction failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c14f3a1",
   "metadata": {},
   "source": [
    "## Step 5: Schema Visualization\n",
    "\n",
    "Display a sample of the extracted schema, filtering out generic classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea808c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'schema_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Display schema sample (excluding generic classes)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m display(\u001b[43mschema_df\u001b[49m[~schema_df.object_class.isin([\u001b[33m\"\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mResource\u001b[39m\u001b[33m\"\u001b[39m])].head(\u001b[32m10\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'schema_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Display schema sample (excluding generic classes)\n",
    "display(schema_df[~schema_df.object_class.isin([\"Class\", \"Resource\"])].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c22a1",
   "metadata": {},
   "source": [
    "## Step 6: Analyze PubChem MeSH Classes\n",
    "\n",
    "Examine the available classes and analyze MeSH-specific structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"PubChem MeSH Schema Analysis (Complete Mode):\")\n",
    "    print(f\"Total unique classes: {schema_df['subject_class'].nunique()}\")\n",
    "    \n",
    "    # Show top classes by frequency\n",
    "    print(\"\\nTop 10 classes by property count:\")\n",
    "    class_counts = schema_df['subject_class'].value_counts().head(10)\n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"  {cls:30} ({count} properties)\")\n",
    "    \n",
    "    # Look for MeSH-specific classes\n",
    "    mesh_classes = schema_df[schema_df['subject_class'].str.contains('mesh|MeSH', case=False, na=False)]['subject_class'].unique()\n",
    "    if len(mesh_classes) > 0:\n",
    "        print(f\"\\nMeSH-specific classes found:\")\n",
    "        for cls in mesh_classes[:10]:\n",
    "            print(f\"  - {cls}\")\n",
    "            \n",
    "        # Analyze first MeSH class in detail\n",
    "        first_mesh_class = mesh_classes[0]\n",
    "        mesh_schema = schema_df[schema_df['subject_class'] == first_mesh_class]\n",
    "        print(f\"\\n{first_mesh_class} Properties:\")\n",
    "        for _, row in mesh_schema.head(10).iterrows():\n",
    "            print(f\"  {row['property']:25} -> {row['object_class']}\")\n",
    "    else:\n",
    "        print(\"\\nNo MeSH-specific classes found in top results\")\n",
    "        print(\"Available classes sample:\")\n",
    "        for cls in schema_df['subject_class'].unique()[:15]:\n",
    "            print(f\"  - {cls}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"MeSH analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27a8da",
   "metadata": {},
   "source": [
    "## Step 7: Export Complete Schema\n",
    "\n",
    "Export the complete schema as JSON and CSV files with detailed statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Export as JSON\n",
    "    print(\"Generating JSON schema (complete mode)...\")\n",
    "    schema_json = parser.to_json(filter_void_nodes=True)\n",
    "    \n",
    "    print(\"Complete JSON export completed\")\n",
    "    print(f\"Total triples: {schema_json['metadata']['total_triples']}\")\n",
    "    print(f\"Classes: {len(schema_json['metadata']['classes'])}\")\n",
    "    print(f\"Properties: {len(schema_json['metadata']['properties'])}\")\n",
    "    print(f\"Object types: {len(schema_json['metadata']['objects'])}\")\n",
    "    \n",
    "    # Save JSON to file\n",
    "    import json\n",
    "    with open(f\"{dataset_name}_schema.json\", \"w\") as f:\n",
    "        json.dump(schema_json, f, indent=2)\n",
    "    print(f\"\\nComplete JSON schema saved to: {dataset_name}_schema.json\")\n",
    "    \n",
    "    # Export as CSV\n",
    "    schema_df.to_csv(f\"{dataset_name}_schema.csv\", index=False)\n",
    "    print(f\"Complete CSV schema saved to: {dataset_name}_schema.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Export failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdfsolve-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
