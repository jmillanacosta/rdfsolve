{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1c8809",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<style>\n",
    "\n",
    "/* Main content area */\n",
    ".jp-RenderedHTMLCommon {\n",
    "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans', Helvetica, Arial, sans-serif;\n",
    "    line-height: 1.6;\n",
    "    color: #24292f;\n",
    "}\n",
    "\n",
    "/* Headers */\n",
    ".jp-RenderedHTMLCommon h1 {\n",
    "    border-bottom: 1px solid #d1d9e0;\n",
    "    padding-bottom: 8px;\n",
    "    margin-bottom: 16px;\n",
    "    font-weight: 600;\n",
    "    color: #1f2328;\n",
    "}\n",
    "\n",
    ".jp-RenderedHTMLCommon h2 {\n",
    "    border-bottom: 1px solid #d8dee4;\n",
    "    padding-bottom: 6px;\n",
    "    margin-top: 24px;\n",
    "    margin-bottom: 16px;\n",
    "    font-weight: 600;\n",
    "    color: #1f2328;\n",
    "}\n",
    "\n",
    ".jp-RenderedHTMLCommon h3 {\n",
    "    margin-top: 20px;\n",
    "    margin-bottom: 12px;\n",
    "    font-weight: 600;\n",
    "    color: #1f2328;\n",
    "}\n",
    "\n",
    "/* Code blocks and inline code */\n",
    ".jp-RenderedHTMLCommon code {\n",
    "    background-color: #f6f8fa;\n",
    "    border-radius: 6px;\n",
    "    padding: 2px 6px;\n",
    "    font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;\n",
    "    font-size: 85%;\n",
    "    color: #1f2328;\n",
    "}\n",
    "\n",
    ".jp-RenderedHTMLCommon pre {\n",
    "    background-color: #f6f8fa;\n",
    "    border-radius: 6px;\n",
    "    padding: 16px;\n",
    "    overflow: auto;\n",
    "    font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;\n",
    "    font-size: 85%;\n",
    "    line-height: 1.45;\n",
    "}\n",
    "\n",
    "/* Lists */\n",
    ".jp-RenderedHTMLCommon ul, .jp-RenderedHTMLCommon ol {\n",
    "    margin-bottom: 16px;\n",
    "}\n",
    "\n",
    ".jp-RenderedHTMLCommon li {\n",
    "    margin-bottom: 4px;\n",
    "}\n",
    "\n",
    "/* Links */\n",
    ".jp-RenderedHTMLCommon a {\n",
    "    color: #0969da;\n",
    "    text-decoration: none;\n",
    "}\n",
    "\n",
    ".jp-RenderedHTMLCommon a:hover {\n",
    "    text-decoration: underline;\n",
    "}\n",
    "\n",
    "/* Tables */\n",
    ".jp-RenderedHTMLCommon table {\n",
    "    border-collapse: collapse;\n",
    "    border-spacing: 0;\n",
    "    width: 100%;\n",
    "    margin-bottom: 16px;\n",
    "}\n",
    "\n",
    ".jp-RenderedHTMLCommon th,\n",
    ".jp-RenderedHTMLCommon td {\n",
    "    padding: 6px 13px;\n",
    "    border: 1px solid #d1d9e0;\n",
    "    text-align: left;\n",
    "}\n",
    "\n",
    ".jp-RenderedHTMLCommon th {\n",
    "    background-color: #f6f8fa;\n",
    "    font-weight: 600;\n",
    "}\n",
    "\n",
    ".jp-RenderedHTMLCommon tr:nth-child(2n) {\n",
    "    background-color: #f6f8fa;\n",
    "}\n",
    "\n",
    "/* Blockquotes */\n",
    ".jp-RenderedHTMLCommon blockquote {\n",
    "    border-left: 4px solid #d1d9e0;\n",
    "    padding-left: 16px;\n",
    "    margin-left: 0;\n",
    "    color: #656d76;\n",
    "}\n",
    "\n",
    "/* Emphasized text */\n",
    ".jp-RenderedHTMLCommon strong {\n",
    "    font-weight: 600;\n",
    "}\n",
    "\n",
    ".jp-RenderedHTMLCommon em {\n",
    "    font-style: italic;\n",
    "}\n",
    "\n",
    "/* Output areas - DataFrames and plots */\n",
    ".jp-OutputArea-output table {\n",
    "    font-size: 12px;\n",
    "    border-collapse: collapse;\n",
    "    margin: 8px 0;\n",
    "}\n",
    "\n",
    ".jp-OutputArea-output th {\n",
    "    background-color: #f1f3f4;\n",
    "    padding: 8px;\n",
    "    text-align: left;\n",
    "    font-weight: 500;\n",
    "    border: 1px solid #dadce0;\n",
    "}\n",
    "\n",
    ".jp-OutputArea-output td {\n",
    "    padding: 6px 8px;\n",
    "    border: 1px solid #dadce0;\n",
    "    max-width: 200px;\n",
    "    overflow: hidden;\n",
    "    text-overflow: ellipsis;\n",
    "    white-space: nowrap;\n",
    "}\n",
    "\n",
    "/* Status indicators */\n",
    ".status-success {\n",
    "    color: #1a7f37;\n",
    "    font-weight: 500;\n",
    "}\n",
    "\n",
    ".status-warning {\n",
    "    color: #9a6700;\n",
    "    font-weight: 500;\n",
    "}\n",
    "\n",
    ".status-error {\n",
    "    color: #d1242f;\n",
    "    font-weight: 500;\n",
    "}\n",
    "\n",
    "/* Schema pattern labels */\n",
    ".schema-pattern {\n",
    "    font-family: 'SFMono-Regular', Consolas, monospace;\n",
    "    background-color: #f6f8fa;\n",
    "    padding: 2px 4px;\n",
    "    border-radius: 3px;\n",
    "    font-size: 90%;\n",
    "}\n",
    "\n",
    "/* Export links styling */\n",
    ".exports-list a {\n",
    "    display: inline-block;\n",
    "    margin-right: 12px;\n",
    "    padding: 4px 8px;\n",
    "    background-color: #f3f4f6;\n",
    "    border-radius: 6px;\n",
    "    border: 1px solid #d1d9e0;\n",
    "    text-decoration: none;\n",
    "    font-size: 14px;\n",
    "    font-weight: 500;\n",
    "}\n",
    "\n",
    ".exports-list a:hover {\n",
    "    background-color: #e1e4e8;\n",
    "    text-decoration: none;\n",
    "}\n",
    "\n",
    "/* Plotly chart container */\n",
    ".plotly-graph-div {\n",
    "    border: 1px solid #e1e4e8;\n",
    "    border-radius: 6px;\n",
    "    margin: 16px 0;\n",
    "}\n",
    "\n",
    "/* Cache status indicators */\n",
    ".cache-info {\n",
    "    font-family: 'SFMono-Regular', Consolas, monospace;\n",
    "    font-size: 12px;\n",
    "    color: #656d76;\n",
    "    background-color: #f6f8fa;\n",
    "    padding: 8px;\n",
    "    border-radius: 6px;\n",
    "    border-left: 3px solid #0969da;\n",
    "}\n",
    "\n",
    "/* Notebook section dividers */\n",
    ".section-divider {\n",
    "    height: 1px;\n",
    "    background: linear-gradient(to right, transparent, #d1d9e0, transparent);\n",
    "    margin: 32px 0;\n",
    "}\n",
    "\n",
    "/* Print styles */\n",
    "@media print {\n",
    "    .jp-RenderedHTMLCommon {\n",
    "        color: #000;\n",
    "    }\n",
    "    \n",
    "    .jp-RenderedHTMLCommon a {\n",
    "        color: #000;\n",
    "        text-decoration: underline;\n",
    "    }\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d16b10",
   "metadata": {},
   "source": [
    "# chebi Schema Extraction\n",
    "\n",
    "This notebook demonstrates RDF schema extraction from the chebi SPARQL endpoint. It discovers VoID (Vocabulary of Interlinked Datasets) descriptions and generates  JSON-LD as the source for all downstream outputs including frequency analysis and LinkML schemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5492f",
   "metadata": {},
   "source": [
    "## Exports\n",
    "\n",
    "- [JSON-LD Schema](https://github.com/jmillanacosta/rdfsolve/blob/main/data/schema_extraction/chebi_schema/chebi_schema.jsonld) (primary output)\n",
    "- [N-Quads RDF](https://github.com/jmillanacosta/rdfsolve/blob/main/data/schema_extraction/chebi_schema/chebi_schema.nq)\n",
    "- [VoID Graph](https://github.com/jmillanacosta/rdfsolve/blob/main/data/schema_extraction/chebi_schema/chebi_generated_void.ttl) for the dataset in its original source\n",
    "- [Coverage report](https://github.com/jmillanacosta/rdfsolve/blob/main/data/schema_extraction/chebi_schema/chebi_pattern_coverage.csv)\n",
    "- [LinkML Schema](https://github.com/jmillanacosta/rdfsolve/blob/main/data/schema_extraction/chebi_schema/chebi_linkml_schema.yaml)\n",
    "- [Full parquet entity dataframe](https://github.com/jmillanacosta/rdfsolve/blob/main/data/schema_extraction/chebi_schema/chebiinstances.parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ded37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Configuration\n",
    "import os\n",
    "\n",
    "# Dataset parameters\n",
    "endpoint_url = \"https://idsm.elixir-czech.cz/sparql/endpoint/idsm\"\n",
    "dataset_name = \"chebi\"\n",
    "void_iri = \"http://rdf.ebi.ac.uk/dataset/chebi\"\n",
    "graph_uri = \"http://rdf.ebi.ac.uk/dataset/chebi\"\n",
    "\n",
    "# Setup paths\n",
    "working_path = os.path.abspath(\"\")\n",
    "exports_path = os.path.join(working_path, \"..\", \"..\", \"data\", \"schema_extraction\", dataset_name)\n",
    "os.makedirs(exports_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Minimal notebook logger using existing dataset_name\n",
    "logger = logging.getLogger(dataset_name or \"notebook\")\n",
    "logger.setLevel(logging.DEBUG)  # Set to DEBUG to see SPARQL queries\n",
    "\n",
    "# Also configure the rdfsolve.parser logger to see query details\n",
    "parser_logger = logging.getLogger('rdfsolve.parser')\n",
    "parser_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Avoid adding duplicate handlers if the cell is re-run\n",
    "if not logger.handlers:\n",
    "    fmt = logging.Formatter(\"%(asctime)s %(levelname)s %(name)s: %(message)s\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    sh = logging.StreamHandler(sys.stdout)\n",
    "    sh.setLevel(logging.DEBUG)  # Set to DEBUG to see all logs\n",
    "    sh.setFormatter(fmt)\n",
    "    logger.addHandler(sh)\n",
    "    \n",
    "    # Add the same handler to the parser logger\n",
    "    parser_logger.addHandler(sh)\n",
    "\n",
    "logger.info(f\"Logging configured for {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cfa4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "from rdfsolve.parser import VoidParser\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Configure Plotly for HTML output\n",
    "import plotly.io as pio\n",
    "import plotly.offline as pyo\n",
    "\n",
    "# Set renderer to 'notebook' for Jupyter, but ensure HTML export works\n",
    "pio.renderers.default = \"notebook+plotly_mimetype\"\n",
    "\n",
    "# Initialize offline mode for Plotly\n",
    "pyo.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d243f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle caching utilities\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def save_cache(data, filename, cache_dir=None):\n",
    "    \"\"\"Save data to pickle cache\"\"\"\n",
    "    if cache_dir is None:\n",
    "        cache_dir = os.path.join(exports_path, \"cache\")\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    cache_path = os.path.join(cache_dir, f\"{filename}.pkl\")\n",
    "    with open(cache_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Cached data to: {cache_path}\")\n",
    "    return cache_path\n",
    "\n",
    "def load_cache(filename, cache_dir=None):\n",
    "    \"\"\"Load data from pickle cache if it exists\"\"\"\n",
    "    if cache_dir is None:\n",
    "        cache_dir = os.path.join(exports_path, \"cache\")\n",
    "    \n",
    "    cache_path = os.path.join(cache_dir, f\"{filename}.pkl\")\n",
    "    if os.path.exists(cache_path):\n",
    "        with open(cache_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f\"Loaded cached data from: {cache_path}\")\n",
    "        return data\n",
    "    return None\n",
    "\n",
    "def cache_exists(filename, cache_dir=None):\n",
    "    \"\"\"Check if cache file exists\"\"\"\n",
    "    if cache_dir is None:\n",
    "        cache_dir = os.path.join(exports_path, \"cache\")\n",
    "    \n",
    "    cache_path = os.path.join(cache_dir, f\"{filename}.pkl\")\n",
    "    return os.path.exists(cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache management utilities\n",
    "def list_cache_files(cache_dir=None):\n",
    "    \"\"\"List all cache files\"\"\"\n",
    "    if cache_dir is None:\n",
    "        cache_dir = os.path.join(exports_path, \"cache\")\n",
    "    \n",
    "    if not os.path.exists(cache_dir):\n",
    "        print(\"No cache directory found\")\n",
    "        return []\n",
    "    \n",
    "    cache_files = [f for f in os.listdir(cache_dir) if f.endswith('.pkl')]\n",
    "    print(f\"Cache directory: {cache_dir}\")\n",
    "    for f in cache_files:\n",
    "        file_path = os.path.join(cache_dir, f)\n",
    "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\"  {f} ({size_mb:.2f} MB)\")\n",
    "    return cache_files\n",
    "\n",
    "def clear_cache(filename=None, cache_dir=None):\n",
    "    \"\"\"Clear specific cache file or all cache\"\"\"\n",
    "    if cache_dir is None:\n",
    "        cache_dir = os.path.join(exports_path, \"cache\")\n",
    "    \n",
    "    if filename:\n",
    "        cache_path = os.path.join(cache_dir, f\"{filename}.pkl\")\n",
    "        if os.path.exists(cache_path):\n",
    "            os.remove(cache_path)\n",
    "            print(f\"Removed cache: {filename}\")\n",
    "        else:\n",
    "            print(f\"Cache not found: {filename}\")\n",
    "    else:\n",
    "        # Clear all cache files\n",
    "        if os.path.exists(cache_dir):\n",
    "            import shutil\n",
    "            shutil.rmtree(cache_dir)\n",
    "            print(f\"Cleared all cache files\")\n",
    "        else:\n",
    "            print(\"No cache directory to clear\")\n",
    "\n",
    "# Show current cache status\n",
    "list_cache_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd27dea",
   "metadata": {},
   "source": [
    "### Cache Control\n",
    "\n",
    "Use these cells to manage cached data. When testing new code changes, you may want to clear relevant cache files to force re-computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cfb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear specific cache files (uncomment lines as needed for testing)\n",
    "\n",
    "# When testing new parser changes:\n",
    "#clear_cache(f\"{dataset_name}_voidparser\")\n",
    "\n",
    "# When testing JSON-LD generation (primary output):\n",
    "#clear_cache(f\"{dataset_name}_jsonld_schema\")\n",
    "\n",
    "# When testing frequency calculations:\n",
    "# clear_cache(f\"{dataset_name}_frequencies_basic\")\n",
    "# clear_cache(f\"{dataset_name}_frequencies_with_instances\")\n",
    "\n",
    "# Clear everything:\n",
    "#clear_cache()\n",
    "\n",
    "print(\"Cleared parser and JSON-LD caches to test schema pattern fix\")\n",
    "print(\"Note: JSON-LD cache is now the primary cache - clear it when testing schema changes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce8103",
   "metadata": {},
   "source": [
    "## Discover or get VoID Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate VoID schema with caching\n",
    "cache_key = f\"{dataset_name}_voidparser\"\n",
    "\n",
    "# Try to load from cache first\n",
    "vp = load_cache(cache_key)\n",
    "\n",
    "if vp is None:\n",
    "    print(\"VoidParser not found in cache, generating...\")\n",
    "    vp = VoidParser.from_endpoint_with_discovery(\n",
    "        endpoint_url=endpoint_url,\n",
    "        dataset_name=dataset_name,\n",
    "        exports_path=exports_path,\n",
    "        # Arguments for the case when a suitable VoID is not found\n",
    "        graph_uris=[graph_uri] if graph_uri else None,\n",
    "        exclude_graph_patterns=[\"openlinksw\",\n",
    "                                \"well-known\",\n",
    "                                \"void\",\n",
    "                                \"service\"], # Filter out service description and administrative graphs\n",
    "        counts=True,\n",
    "        offset_limit_steps=300 # pagination\n",
    "    )\n",
    "    # Cache the VoidParser for future use\n",
    "    save_cache(vp, cache_key)\n",
    "else:\n",
    "    print(\"Loaded VoidParser from cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e848a08",
   "metadata": {},
   "source": [
    "## Schema Discovery and Exports Workflow\n",
    "\n",
    "### Workflow Steps:\n",
    "\n",
    "1. **VoID Discovery**: Extract schema patterns from SPARQL endpoint VoID descriptions\n",
    "2. **JSON-LD Generation**: Convert to JSON-LD.\n",
    "3. **Derived Outputs**: All other formats are generated from the JSON-LD structure:\n",
    "   - **Frequencies**: Schema pattern coverage analysis\n",
    "   - **LinkML**: LinkML YAML used elsewhere for other features.\n",
    "   - **CSV/JSON**: Tabular and structured data exports\n",
    "   - **RDF**: N-Quads serialization for triplestore import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b09ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary JSON-LD schema export and basic summary\n",
    "cache_key = f\"{dataset_name}_jsonld_schema\"\n",
    "jsonld_schema = load_cache(cache_key)\n",
    "\n",
    "if jsonld_schema is None:\n",
    "    print(\"Generating standards-compliant JSON-LD schema...\")\n",
    "    jsonld_schema = vp.to_jsonld(filter_void_admin_nodes=True)\n",
    "    save_cache(jsonld_schema, cache_key)\n",
    "else:\n",
    "    print(\"Loaded JSON-LD schema from cache\")\n",
    "\n",
    "# Save JSON-LD schema file\n",
    "jsonld_file = os.path.join(exports_path, f\"{dataset_name}_schema.jsonld\")\n",
    "with open(jsonld_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(jsonld_schema, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"JSON-LD Schema saved to: {jsonld_file}\")\n",
    "\n",
    "# Display combined JSON-LD structure info and schema summary\n",
    "if \"@graph\" in jsonld_schema:\n",
    "    print(f\"\\nSchema Summary:\")\n",
    "    print(f\"   • Prefixes: {len(jsonld_schema['@context'])}\")\n",
    "    print(f\"   • Resources: {len(jsonld_schema['@graph'])}\")\n",
    "    \n",
    "    # Show dataset metadata\n",
    "    dataset_info = jsonld_schema[\"@graph\"][0] if jsonld_schema[\"@graph\"] else {}\n",
    "    if dataset_info.get(\"@type\") == \"void:Dataset\":\n",
    "        print(f\"   • Dataset: {dataset_info.get('dcterms:title', 'Unknown')}\")\n",
    "        print(f\"   • Classes: {dataset_info.get('void:classes', 0)}\")\n",
    "        print(f\"   • Properties: {dataset_info.get('void:properties', 0)}\")\n",
    "        print(f\"   • Triples: {dataset_info.get('void:triples', 0)}\")\n",
    "\n",
    "# Get schema DataFrame and show sample\n",
    "schema_df = vp.to_schema(filter_void_admin_nodes=True)\n",
    "print(f\"\\nSchema Patterns Preview ({len(schema_df)} total):\")\n",
    "display(schema_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a530dd",
   "metadata": {},
   "source": [
    "## Schema Pattern Coverage Analysis\n",
    "Calculate coverage ratios showing what percentage of entities use each relationship pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b864b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema pattern coverage analysis and export\n",
    "cache_key = f\"{dataset_name}_frequencies_basic\"\n",
    "cached_data = load_cache(cache_key)\n",
    "\n",
    "if cached_data is None:\n",
    "    print(\"Calculating schema pattern frequencies...\")\n",
    "    frequencies_df, _ = vp.count_schema_shape_frequencies(\n",
    "        endpoint_url=endpoint_url,\n",
    "        offset_limit_steps=300,\n",
    "    )\n",
    "    save_cache(frequencies_df, cache_key)\n",
    "else:\n",
    "    print(\"Loaded frequencies DataFrame from cache\")\n",
    "    frequencies_df = cached_data\n",
    "\n",
    "# Export coverage analysis\n",
    "frequencies_output_path = os.path.join(exports_path, f\"{dataset_name}_pattern_coverage.csv\")\n",
    "exported_df = vp.export_schema_shape_frequencies(frequencies_df, output_file=frequencies_output_path)\n",
    "\n",
    "# Combined summary and sample\n",
    "if not frequencies_df.empty:\n",
    "    avg_coverage = frequencies_df['coverage_percent'].mean()\n",
    "    high_coverage = (frequencies_df['coverage_percent'] > 50).sum()\n",
    "    \n",
    "    print(f\"\\nPattern Coverage Analysis:\")\n",
    "    print(f\"   • Total patterns: {len(frequencies_df)}\")\n",
    "    print(f\"   • Average coverage: {avg_coverage:.1f}%\")\n",
    "    print(f\"   • High coverage (>50%): {high_coverage}\")\n",
    "    print(f\"   • Exported to: {frequencies_output_path}\")\n",
    "    \n",
    "    print(f\"\\nSample Coverage Data:\")\n",
    "    display(frequencies_df[['subject_class', 'property', 'object_class', 'coverage_percent']].head())\n",
    "    \n",
    "    print(f\"\\nCoverage Statistics:\")\n",
    "    display(frequencies_df['coverage_percent'].describe())\n",
    "else:\n",
    "    print(\"No frequency data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a15c1",
   "metadata": {},
   "source": [
    "## Schema Pattern Instance Collection\n",
    "Collect actual subject and object IRI instances for each schema pattern. This provides detailed access to the specific entities participating in each relationship pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5833f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect both frequency data and actual instances with caching\n",
    "cache_key = f\"{dataset_name}_frequencies_with_instances\"\n",
    "cached_data = load_cache(cache_key)\n",
    "\n",
    "if cached_data is None:\n",
    "    print(\"Collecting frequency data and instances...\")\n",
    "    frequencies_with_instances_df, instances_df = vp.count_schema_shape_frequencies(\n",
    "        endpoint_url=endpoint_url,\n",
    "        #sample_limit=100,  # Limited sample for demonstration\n",
    "        collect_instances=True,\n",
    "        offset_limit_steps=300\n",
    "    )\n",
    "    # Cache both DataFrames as a tuple\n",
    "    save_cache((frequencies_with_instances_df, instances_df), cache_key)\n",
    "else:\n",
    "    print(\"Loaded frequencies and instances DataFrames from cache\")\n",
    "    frequencies_with_instances_df, instances_df = cached_data\n",
    "\n",
    "# Display basic information about the data structure\n",
    "print(f\"Frequencies DataFrame: {len(frequencies_with_instances_df)} shapes\")\n",
    "if instances_df is not None:\n",
    "    print(f\"Instances DataFrame: {len(instances_df)} subject-object pairs\")\n",
    "    print(f\"Memory usage - Frequencies: {frequencies_with_instances_df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "    print(f\"Memory usage - Instances: {instances_df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(\"No instances collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db811da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "\n",
    "if not frequencies_df.empty:\n",
    "    df = frequencies_df.copy()\n",
    "    df[\"coverage_percent\"] = pd.to_numeric(\n",
    "        df[\"coverage_percent\"], errors=\"coerce\"\n",
    "    ).fillna(0)\n",
    "    df = df.sort_values(\"coverage_percent\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    def make_label(row):\n",
    "        return (\n",
    "            f\"<b>{row['subject_class']}</b> \"\n",
    "            f\"<span style='color:#888;'></span> \"\n",
    "            f\"<i>{row['property']}</i> \"\n",
    "            f\"<span style='color:#888;'></span> \"\n",
    "            f\"<b>{row['object_class']}</b>\"\n",
    "        )\n",
    "\n",
    "    df[\"styled_label\"] = df.apply(make_label, axis=1)\n",
    "\n",
    "    text_positions = [\"outside\" if v < 95 else \"inside\" for v in df[\"coverage_percent\"]]\n",
    "    custom_colorscale = [\n",
    "        [0.0, \"#d36e61\"],\n",
    "        [0.4, \"#e5cdbd\"],\n",
    "        [0.7, \"#e8e4cf\"],\n",
    "        [1.0, \"#c3d9c0\"],\n",
    "    ]\n",
    "\n",
    "    # Figure sizing\n",
    "    bar_height = 26\n",
    "    fig_height = min(2000, bar_height * len(df) + 200)\n",
    "\n",
    "    fig = go.Figure(\n",
    "        go.Bar(\n",
    "            x=df[\"coverage_percent\"],\n",
    "            y=df[\"styled_label\"],\n",
    "            orientation=\"h\",\n",
    "            text=[f\"{v:.1f}%\" for v in df[\"coverage_percent\"]],\n",
    "            textposition=text_positions,\n",
    "            marker=dict(\n",
    "                color=df[\"coverage_percent\"],\n",
    "                colorscale=custom_colorscale,\n",
    "                cmin=0,\n",
    "                cmax=100,\n",
    "                line=dict(color=\"white\", width=0.6),\n",
    "            ),\n",
    "            hovertemplate=\"<b>%{y}</b><br>Coverage: %{x:.1f}%<extra></extra>\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": f\"Schema Pattern Coverage for {dataset_name}\",\n",
    "            \"x\": 0.5,\n",
    "            \"font\": {\"size\": 18},\n",
    "        },\n",
    "        xaxis=dict(\n",
    "            title=\"Coverage (%)\",\n",
    "            range=[0, 100],  # fixed x-axis range\n",
    "            ticksuffix=\"%\",\n",
    "            showgrid=True,\n",
    "            gridcolor=\"rgba(220,220,220,0.3)\",\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"\",\n",
    "            autorange=\"reversed\",\n",
    "            automargin=True,\n",
    "            fixedrange=False,  # allow vertical zoom/pan\n",
    "        ),\n",
    "        template=\"plotly_white\",\n",
    "        autosize=True,  # allow figure to scale with container\n",
    "        height=fig_height,  # base height (will scale)\n",
    "        margin=dict(t=80, b=50, l=480, r=150),  # extra right margin for text\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "    )\n",
    "\n",
    "    # Disable horizontal zoom/pan\n",
    "    fig.update_xaxes(fixedrange=True)\n",
    "\n",
    "    # Show figure with config for HTML export compatibility\n",
    "    fig.show(config={\n",
    "        \"scrollZoom\": True, \n",
    "        \"responsive\": True,\n",
    "        \"toImageButtonOptions\": {\n",
    "            \"format\": \"png\",\n",
    "            \"filename\": f\"{dataset_name}_schema_coverage\",\n",
    "            \"height\": fig_height,\n",
    "            \"width\": 600,\n",
    "            \"scale\": 1\n",
    "        }\n",
    "    })\n",
    "\n",
    "else:\n",
    "    display(Markdown(\"**No coverage data to visualize**\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9920263",
   "metadata": {},
   "source": [
    "## LinkML (derived from JSON-LD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2baa043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LinkML directly from JSON-LD with custom schema URI\n",
    "print(\"Regenerating LinkML schema from JSON-LD with custom schema URI...\")\n",
    "\n",
    "schema_name = f\"{dataset_name}_schema\"\n",
    "custom_schema_uri = f\"http://jmillanacosta.github.io/rdfsolve/{dataset_name}/linkml\"  # User-definable base URI\n",
    "\n",
    "yaml_text = vp.to_linkml_yaml(\n",
    "    schema_name=schema_name,\n",
    "    schema_description=f\"LinkML schema for {dataset_name} generated from JSON-LD\",\n",
    "    schema_base_uri=custom_schema_uri,\n",
    "    filter_void_nodes=True,\n",
    ")\n",
    "\n",
    "# Save to LinkML YAML\n",
    "linkml_file = os.path.join(exports_path, f\"{dataset_name}_linkml_schema.yaml\")\n",
    "with open(linkml_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(yaml_text)\n",
    "\n",
    "print(f\"LinkML YAML saved to: {linkml_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9197f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linkml.generators.erdiagramgen import ERDiagramGenerator\n",
    "from linkml_runtime.utils.schemaview import SchemaView\n",
    "\n",
    "sv = SchemaView(linkml_file)\n",
    "linkml_schema = sv.schema\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"**Parsed LinkML schema:** Classes = {len(sv.all_classes())}, Slots = {len(sv.all_slots())}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Build and display a Mermaid class diagram for the aopwikirdf LinkedML\n",
    "mermaid_code = ERDiagramGenerator(linkml_file).serialize()\n",
    "\n",
    "display(Markdown(mermaid_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.path.join(exports_path, f\"{dataset_name}_schema.json\")\n",
    "csv_path = os.path.join(exports_path, f\"{dataset_name}_schema.csv\")\n",
    "\n",
    "# Export CSV from frequencies\n",
    "frequencies_df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Export JSON derived from JSON-LD (maintains consistency)\n",
    "with open(json_path, 'w', encoding='utf-8') as fh:\n",
    "    json.dump(vp.to_json(filter_void_nodes=True), fh, indent=2)\n",
    "\n",
    "print(f\"CSV exported to: {csv_path}\")\n",
    "print(f\"JSON exported to: {json_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
